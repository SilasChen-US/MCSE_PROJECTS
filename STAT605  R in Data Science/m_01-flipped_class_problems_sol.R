# -----------------------------------------------------------------------------
# *********** Flipped class problems for Module 1
# -----------------------------------------------------------------------------


# -----------------------------------------------------------------------------
# **** Operations with vectors
# -----------------------------------------------------------------------------


# -----------------------------------------------------------------------------
# ** Given two equally sized numerical vectors, implement
#    a general inner product (dot product, projection product)
#    of them in a function called
#    `inner_product` (use the stock function %*% only to **verify**
#    the correctness of your result).
#    Apply it to the example given below.
a <- c( 3, -4, 12)
b <- c(-3,  2,  5)
# NOTE!!! Your results should work for vectors of ANY dimension, not only
#         for 3-dimensional vectors. Also, you cannot use loops.
#         The same applies to the next five problems dealing with vectors.

# * Begin solution
inner_product <- function(a, b) {
  sum(a*b)
}

inner_product(a, b)
# Verify with stock function
a %*% b
# * End solution


# -----------------------------------------------------------------------------
# ** Using the implemented `inner_product` function, create the function
#    `vect_norm` that implements the euclidean norm of a vector
#    Apply it to vector `a`


# * Begin solution
vect_norm <- function(a) {
  sqrt(inner_product(a, a))
}

vect_norm(a)
# Verify with stock function
sqrt(a %*% a)
# * End solution


# -----------------------------------------------------------------------------
# ** Implement the Taxicab norm (or Manhattan norm, l^1 norm, l_1 distance)
#    in the function `taxicab_norm`. For details, see 
#    https://en.wikipedia.org/wiki/Norm_(mathematics)#Taxicab_norm_or_Manhattan_norm


# * Begin solution
taxicab_norm <- function(a) {
  sum(abs(a))
}

taxicab_norm(a)
# * End solution


# -----------------------------------------------------------------------------
# ** Implement the p-norm (l_p norm) in the function
#    `p_norm`. For details, see 
#    https://en.wikipedia.org/wiki/Norm_(mathematics)#p-norm

# * Begin solution
p_norm <- function(a, p) {
  sum(abs(a)^p)^(1/p)
}

p_norm(a, 2)  # Check that the 2-norm is the common norm
p_norm(a, 5)  # 5-norm
# * End solution


# -----------------------------------------------------------------------------
# ** Implement the maximum norm in the function
#    `max_norm`. For details, see 
# https://en.wikipedia.org/wiki/Norm_(mathematics)#Maximum_norm_(special_case_of:_infinity_norm,_uniform_norm,_or_supremum_norm)


# * Begin solution
max_norm <- function(a) {
  max(abs(a))
}

max_norm(a)
# * End solution


# -----------------------------------------------------------------------------
# ** Implement the Minkowski distance in the function
#    `minkowski_dist`. For details, see 
#    https://en.wikipedia.org/wiki/Minkowski_distance


# * Begin solution
minkowski_dist <- function(a, b, p) {
  sum(abs(a - b)^p)^(1/p)
}

minkowski_dist(a, b, 2)  # Common distance between vectors (Euclidean distance)
minkowski_dist(a, b, 5)

euclidean_distance <- function(a, b) minkowski_dist(a, b, 2)

euclidean_distance(a, b)
# * End solution


# -----------------------------------------------------------------------------
# ** Given the vector
set.seed(1)
(x <- rgamma(20, shape = 3, rate = 2)) # random variate from a gamma distr.
#    find the cumulative sum, the cumulative product, the cumulative minimum,
#    and cumulative maximum. You can use functions provided by R.


# * Begin solution
cumsum(x)
cumprod(x)
cummin(x)
cummax(x)
# * End solution


# -----------------------------------------------------------------------------
# ** Given the vector
x <- 20:1
#    find the cumulative average. It has to be a one liner.
#    You cannot use `mean`, nor loops.


# * Begin solution
# 3 possibilities
cumsum(x)/cumsum(rep(1, length(x)))
cumsum(x)/(1:length(x))
cumsum(x)/seq_along(x)
# * End solution



# -----------------------------------------------------------------------------
# ** Given the vector generated by
set.seed(1)
x <- rgamma(200, shape = 3, rate = 2) # random variate from a gamma distr.
#    find its *approximate* (empirical) cumulative probability distribution
#    You must use the function `cumtrapz` of the `pracma` package.
#    Plot the obtained function.
#    You can compare its plot to the one obtained using pgamma(),
#    that calculates the cumulative prob. distr. for any given quantile.
#    You can (and should) use the function `dgamma` to obtain the densities
#    corresponding to the x values.


# * Begin solution
library(pracma)
sx <- sort(x)
sxy <- dgamma(sx, shape = 3, rate = 2)
plot(sx, sxy, type = "l")            # Plot of function to integrate

(cumprob <- cumtrapz(sx, sxy))       # Approximate cumulative distribution
plot(sx, cumprob, type = "l")        # Plot it
lines(sx, pgamma(sx, shape = 3, rate = 2), col = "red")  # Using stock function
# * End solution


# -----------------------------------------------------------------------------
# **** Sub-setting
# -----------------------------------------------------------------------------


# Run the following code (the commented one only once) to access
# the father.son data set.
# install.packages("UsingR")
library(UsingR)

# Pearson's data (heights of father and corresponding son)
# father.son is a data.frame. For now, ignore that fact (we are going to
# cover the details in a future lecture).
# We are going to extract two numerical vectors and work with that.
data(father.son)
dim(father.son)    # Rows and columns
str(father.son)    # Show structure
head(father.son)   # First six pairs
tail(father.son)   # Last six pairs

# Assigning to object names, and forgetting about the data.frame
fheight <- father.son$fheight
sheight <- father.son$sheight

# First ten values of the vectors we are going to use
fheight[1:10]
sheight[1:10]


# -----------------------------------------------------------------------------
# ** Using positive indexes extract a *random sample* 50 values from the vector
#    `fheigh`.
#    Also extract a *simple random sample* of size 50
#    (Hint: use function `sample`).
#    Note: use `sample` to generate the indexes, not to extract the values
#          directly. This way, if later you would like to do, for example,
#          a regression, analysis on the subset, you could easily extract
#          the corresponding son's heights.


# * Begin solution
set.seed(1)   # Fix a seed to make it reproducible
# Random sample (corresponding indexes)
ndx_rs <- sample(1:length(x), 50, replace = TRUE)
rs <- fheight[ndx_rs]

set.seed(1)   # Fix a seed to make it reproducible
# Simple random sample (the default of `sample`)
srs <- fheight[ndx_srs <- sample(1:length(x), 50, replace = FALSE)]
# Notice here I am assigning inside the indexing of the vector.
# This is done so you know it can be done, which does not mean you should do it,
# as it can be confusing and potentially error prone
# (R will not be confused, but you might...). Use you best judgment.

rs
srs
# As you can verify, elements index 21 and from index 39 are different
rs - srs
(tbl <- table(rs))
# One outcome, 67.16724, is repeated in the first scheme
tbl[tbl > 1]

# From the indexes point of view
ndx_rs
ndx_srs
# As you can verify, index 21 and from index 39 are different
ndx_rs - ndx_srs
(tbl <- table(ndx_rs))
# One outcome, 67.16724, is repeated in the first scheme
tbl[tbl > 1]
# * End solution


# -----------------------------------------------------------------------------
# ** Using logical indexes find those cases where the son's height differs from
#    the father's height by at least 3 inches (in excess or in defect).
#    Of this subset, find out how many cases had son taller and how many shorter
#    than father


# * Begin solution
ndx <- (1:length(sheight))[abs(sheight - fheight) >= 3]
# Notice 1: indexing directly in the generation of the sequence.
#           You do not need to have an object name to index.
#           Again, that you can do it does not imply you should do it
#           ("clear intention" code may be preferable to 
#            "look how convoluted I can be" code unless a gain in performance
#           is critically needed in code that is run permanently).
# Notice 2: inside the square bracket, the expression evaluates to a logical
#           and that logical is used in the indexing.

table((sheight - fheight)[ndx] > 0)
table((sheight[ndx] - fheight[ndx]) > 0) # Alternative
# TRUE cases are son taller than father
# * End solution


# -----------------------------------------------------------------------------
# ** Using logical indexes, verify the "Empirical rule", that states that when data
#    is drawn from a Normal distribution,

# * about 68% of the data is in the interval
#   `(mean(x) - sd(x), mean(x) + sd(x))`
# * about 95% of the data is in the interval
#   `(mean(x) - 2 * sd(x), mean(x) + 2 * sd(x))`
# * about 99.7% of the data is in the interval
#   `(mean(x) - 3 * sd(x), mean(x) + 3 * sd(x))`
# Hint: use "x <- rnorm(n)" to randomly generate a sample of size n from a standard
#       normal distribution. Use n = $1000$
  
# * Begin solution
n <- 1000
x <- rnorm(n)
hist(x)  # To visually assess that x it is normally distributed

x_bar <- mean(x)
s <- sd(x)
length(x[x > x_bar - s & x < x_bar + s]) / n * 100
length(x[x > x_bar - 2 * s & x < x_bar + 2 * s]) / n * 100
length(x[x > x_bar - 3 * s & x < x_bar + 3 * s]) / n * 100
# * End solution


# -----------------------------------------------------------------------------
# ** Using negative indexes, starting from the data below
data("BJsales")
help(BJsales)
#    that is a time series object (`ts) that we coerce to a numeric vector
sales <- as.numeric(BJsales)
#    using negative indexes find:
#    1) the first differences (explanation in link)
#       https://people.duke.edu/~rnau/411diff.htm#firstdiff
#       You can verify that the result should match the one of
#       the function `diff`
#    2) the one period simple return R_t
#    3) the continuously compounded return r_t
#    For 2) and 3) see page 10 of pdf added to flipped class module
#       (below this script)
#    Round 2) and 3) to 4 decimals.


# * Begin solution
# 1)
sales[-1] - sales[-length(sales)]
diff(sales, lag = 1)

# 2)
round((sales[-1] - sales[-length(sales)])/sales[-length(sales)], 5)

# 3)
round(log(sales[-1]/sales[-length(sales)]), 5)
# * End solution

